{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Convolutional Layer\n",
    "\n",
    "Convolutional layer is a feedforward layer that satisfies the following additional properties:\n",
    "* sparse connectivity - each neuron is connected with every channel of a small spatial region of the input\n",
    "* shared parameters - each neuron within layer uses the same parameters\n",
    "\n",
    "This notebook will not cover details of convolution arithmetic.\n",
    "Instead it focuses on Tensorflow's implementation and practical examples.\n",
    "For intuition behind convolutional operation, refer to the lecture slides.\n",
    "For mathematical details of convolutional operation, an excellent source would be:\n",
    "https://arxiv.org/abs/1603.07285\n",
    "\n",
    "In convolutional layers, it's very important to get a good grasp on the dimensions of inputs, filters, and outputs. To discuss dimensionality, we will use the following conventions in this notebook:\n",
    "* $ n^{[l]}_h $ - activation height of layer $l$, or of input image if $l = 0$\n",
    "* $ n^{[l]}_w $ - activation width of layer $l$, or of input image if $l = 0$\n",
    "* $ n^{[l]}_c $ - activation depth of layer $l$, or of input image if $l = 0$\n",
    "* $ f^{[l]} $ - height and width of a filter in layer $l$ (typically, the same across both dimensions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Convolution (1 input channel, 1 output channel)\n",
    "\n",
    "The key to understanding the relationship between dimensions of the input and of the output in a convolutional layer is to consider the basic case with 1 input and 1 output channels. Given input of shape $ n^{[l-1]}_h \\times n^{[l-1]}_w $ and filter of shape $ f^{[l]} \\times f^{[l]} $, the shape of the output of a convolution with padding $p$ and stride $s$: \n",
    "\n",
    "$ \\text{Convolution}\\big( n^{[l-1]}_h \\times n^{[l-1]}_w, f^{[l]} \\times f^{[l]} \\big) \\rightarrow n^{[l]}_h \\times n^{[l]}_w $\n",
    "\n",
    "$ n^{[l]}_h = \\big\\lfloor \\frac{n^{[l-1]}_h + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "$ n^{[l]}_w = \\big\\lfloor \\frac{n^{[l-1]}_w + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "In practive, padding is often specified as either valid or same. Valid padding simply means no padding at all ($p$ = 0), while same padding means as much padding as needed to keep spatial dimensions of the input and of the ouput the same. The exact size of same padding depends on the stride and the spatial dimensions of the input and of the filter. Typically, if the filter is larger, then more padding is needed to keep the spatial dimensions of the output equal to that of the input. Let's see an example of this calculation with Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to configure Tensorflow to use your GPU\n",
    "import tensorflow as tf\n",
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Computes a 2-D convolution given 4-D `input` and `filters` tensors.\n",
       "\n",
       "Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
       "and a filter / kernel tensor of shape\n",
       "`[filter_height, filter_width, in_channels, out_channels]`, this op\n",
       "performs the following:\n",
       "\n",
       "1. Flattens the filter to a 2-D matrix with shape\n",
       "   `[filter_height * filter_width * in_channels, output_channels]`.\n",
       "2. Extracts image patches from the input tensor to form a *virtual*\n",
       "   tensor of shape `[batch, out_height, out_width,\n",
       "   filter_height * filter_width * in_channels]`.\n",
       "3. For each patch, right-multiplies the filter matrix and the image patch\n",
       "   vector.\n",
       "\n",
       "In detail, with the default NHWC format,\n",
       "\n",
       "    output[b, i, j, k] =\n",
       "        sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *\n",
       "                        filter[di, dj, q, k]\n",
       "\n",
       "Must have `strides[0] = strides[3] = 1`.  For the most common case of the same\n",
       "horizontal and vertical strides, `strides = [1, stride, stride, 1]`.\n",
       "\n",
       "Usage Example:\n",
       "\n",
       ">>> x_in = np.array([[\n",
       "...   [[2], [1], [2], [0], [1]],\n",
       "...   [[1], [3], [2], [2], [3]],\n",
       "...   [[1], [1], [3], [3], [0]],\n",
       "...   [[2], [2], [0], [1], [1]],\n",
       "...   [[0], [0], [3], [1], [2]], ]])  \n",
       ">>> kernel_in = np.array([\n",
       "...  [ [[2, 0.1]], [[3, 0.2]] ],\n",
       "...  [ [[0, 0.3]],[[1, 0.4]] ], ])\n",
       ">>> x = tf.constant(x_in, dtype=tf.float32)\n",
       ">>> kernel = tf.constant(kernel_in, dtype=tf.float32)\n",
       ">>> tf.nn.conv2d(x, kernel, strides=[1, 1, 1, 1], padding='VALID')\n",
       "<tf.Tensor: shape=(1, 4, 4, 2), dtype=float32, numpy=..., dtype=float32)>\n",
       "\n",
       "Args:\n",
       "  input: A `Tensor`. Must be one of the following types:\n",
       "    `half`, `bfloat16`, `float32`, `float64`.\n",
       "    A 4-D tensor. The dimension order is interpreted according to the value\n",
       "    of `data_format`, see below for details.\n",
       "  filters: A `Tensor`. Must have the same type as `input`.\n",
       "    A 4-D tensor of shape\n",
       "    `[filter_height, filter_width, in_channels, out_channels]`\n",
       "  strides: An int or list of `ints` that has length `1`, `2` or `4`.  The\n",
       "    stride of the sliding window for each dimension of `input`. If a single\n",
       "    value is given it is replicated in the `H` and `W` dimension. By default\n",
       "    the `N` and `C` dimensions are set to 1. The dimension order is determined\n",
       "    by the value of `data_format`, see below for details.\n",
       "  padding: Either the `string` `\"SAME\"` or `\"VALID\"` indicating the type of\n",
       "    padding algorithm to use, or a list indicating the explicit paddings at\n",
       "    the start and end of each dimension. When explicit padding is used and\n",
       "    data_format is `\"NHWC\"`, this should be in the form `[[0, 0], [pad_top,\n",
       "    pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used\n",
       "    and data_format is `\"NCHW\"`, this should be in the form `[[0, 0], [0, 0],\n",
       "    [pad_top, pad_bottom], [pad_left, pad_right]]`.\n",
       "  data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`.\n",
       "    Defaults to `\"NHWC\"`.\n",
       "    Specify the data format of the input and output data. With the\n",
       "    default format \"NHWC\", the data is stored in the order of:\n",
       "        [batch, height, width, channels].\n",
       "    Alternatively, the format could be \"NCHW\", the data storage order of:\n",
       "        [batch, channels, height, width].\n",
       "  dilations: An int or list of `ints` that has length `1`, `2` or `4`,\n",
       "    defaults to 1. The dilation factor for each dimension of`input`. If a\n",
       "    single value is given it is replicated in the `H` and `W` dimension. By\n",
       "    default the `N` and `C` dimensions are set to 1. If set to k > 1, there\n",
       "    will be k-1 skipped cells between each filter element on that dimension.\n",
       "    The dimension order is determined by the value of `data_format`, see above\n",
       "    for details. Dilations in the batch and depth dimensions if a 4-d tensor\n",
       "    must be 1.\n",
       "  name: A name for the operation (optional).\n",
       "\n",
       "Returns:\n",
       "  A `Tensor`. Has the same type as `input`.\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "?tf.nn.conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# A simple wrapper function around Tensorflow convolution operation\n",
    "# that takes a single input matrix, and a single filter matrix,\n",
    "# and uses same padding and 1-stride.\n",
    "def conv_simple(input_mat, filter_mat):\n",
    "    # Desired input shape = batch, height, width, channel\n",
    "    # so we need to add 0th, and 3rd axes\n",
    "    input_mat = np.expand_dims(input_mat, 0)\n",
    "    input_mat = np.expand_dims(input_mat, 3)\n",
    "    input_tn = tf.constant(input_mat, dtype=tf.float32)\n",
    "    \n",
    "    # Desired filter shape = height, width, in, out\n",
    "    # so we need to add 2nd, and 3rd axes\n",
    "    filter_mat = np.expand_dims(filter_mat, 2)\n",
    "    filter_mat = np.expand_dims(filter_mat, 3)\n",
    "    filter_tn = tf.constant(filter_mat, dtype=tf.float32)\n",
    "\n",
    "    output_tn = tf.nn.conv2d(\n",
    "        input_tn, \n",
    "        strides=[1, 1, 1, 1], \n",
    "        padding='SAME', \n",
    "        filters=filter_tn\n",
    "    )\n",
    "    \n",
    "    return output_tn.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370</td>\n",
       "      <td>470</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>670</td>\n",
       "      <td>770</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230</td>\n",
       "      <td>260</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  370  470  210\n",
       "1  670  770  330\n",
       "2  230  260   90"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "    \n",
    "input_np = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "]\n",
    "\n",
    "filter_np = [\n",
    "    [10, 20],\n",
    "    [30, 40]\n",
    "]\n",
    "\n",
    "output = conv_simple(input_np, filter_np)\n",
    "pd.DataFrame(output[0, :, :, 0]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Convolution (many input channels, 1 output channel)\n",
    "\n",
    "In the case of many input channels, the output dimensions are not affected, because the number of channels in the output depends on the number of channels in the filter. Given input of shape $n^{[l-1]}_h \\times n^{[l-1]}_w \\times n^{[l-1]}_c $ and filter of shape $f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c$, the shape of the output of a convolution with padding $p$ and stride $s$: \n",
    "\n",
    "$\n",
    "\\text{Convolution} \\big( \n",
    "    n^{[l-1]}_h \\times n^{[l-1]}_w \\times n^{[l-1]}_c, \n",
    "    f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c\n",
    "\\big) \n",
    "\\rightarrow n^{[l]}_h \\times n^{[l]}_w \n",
    "$\n",
    "\n",
    "$ n^{[l]}_h = \\big\\lfloor \\frac{n^{[l-1]}_h + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "$ n^{[l]}_w = \\big\\lfloor \\frac{n^{[l-1]}_w + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "Note that the third dimension of the filter has to match the number of channels in the input. When the filter is applied to the input, the input's channels are matched with the filter's channels. Products of corresponding spatial locations are added together across space and channels, which is why the output is still flat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Convolution (many input channels, many output channels)\n",
    "\n",
    "When both input and output has many channels, the calculations are pretty similar but we calculate multiple independent activation maps, which gives depth to the activation tensor. Given input of shape $n^{[l-1]}_h \\times n^{[l-1]}_w \\times n^{[l-1]}_c $ and filter of shape $f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c \\times n^{[l]}_c$, the shape of the output of a convolution with padding $p$ and stride $s$: \n",
    "\n",
    "$\n",
    "\\text{Convolution} \\big( \n",
    "    n^{[l-1]}_h \\times n^{[l-1]}_w \\times n^{[l-1]}_c, \n",
    "    f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c \\times n^{[l]}_c\n",
    "\\big) \n",
    "\\rightarrow n^{[l]}_h \\times n^{[l]}_w \\times n^{[l]}_c\n",
    "$\n",
    "\n",
    "$ n^{[l]}_h = \\big\\lfloor \\frac{n^{[l-1]}_h + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "$ n^{[l]}_w = \\big\\lfloor \\frac{n^{[l-1]}_w + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "Note that the third dimension of the filter has to match the number of channels in the input,\n",
    "while the fourth dimension of the filter matches the number of channels in the output. \n",
    "Spatial dimensions (e.g. the first and the second dimensions) of the output are not affected by the number of channels.\n",
    "When applying the filter to the input, each activation map is calculated independently and then stacked together to produce activation volume. Simply stated, the fourth dimensions of the filter describes a collection of independent filters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collegium",
   "language": "python",
   "name": "collegium"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
