{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "In this assignment, you will be working on an image classification task (codename `pnp`) using the transfer learning technique.\n",
    "The task objective is to determine whether an image contains a person (`pnp` stands for person / non-person) -- a binary classification task.\n",
    "\n",
    "## Dataset\n",
    "* Dataset contains 80K images with known labels (for model development), and 20K images with unknown labels (for scoring).\n",
    "* Dataset has been created from a subset of COCO Dataset, and so all copyrights belong to the original authors: https://cocodataset.org/#termsofuse\n",
    "* Images have been rescaled and padded to be of shape (224, 224, 3).\n",
    "\n",
    "While it's possible to create a new model architecture and train a model specifically for this task, that would be expensive in terms of time and cloud resources.\n",
    "Instead, in this assignment, you will be re-using an pre-trained model's architecture and parameters to save time and cloud resources.\n",
    "\n",
    "## MobileNet Architecture\n",
    "* The pre-trained model's name is MobileNetV2: https://arxiv.org/pdf/1801.04381.pdf\n",
    "* MobileNet is a relatively small network that is designed for usage on mobile devices with limited compute and storage resource.\n",
    "* It's a great choice for this assignment, since this network can be relatively quickly processed with a single GPU.\n",
    "\n",
    "## MobileNet Parameters\n",
    "* Keras provides network architecture and pre-trained parameters: https://keras.io/api/applications/mobilenet/#mobilenetv2-function\n",
    "* The pre-trained parameters come from the ImageNet 1000-class task, which does not include a person label.\n",
    "* The lower part of the network can be reused due to the shared hierarchy of visual information..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/zsh: /root/miniconda3/envs/ucla_deeplearning/lib/libtinfo.so.6: no version information available (required by /bin/zsh)\n",
      "ls: cannot access 'pnp_dataset': No such file or directory\n",
      "wget: /root/miniconda3/envs/ucla_deeplearning/lib/libuuid.so.1: no version information available (required by wget)\n",
      "--2022-09-18 19:10:32--  https://danylo-ucla.s3.us-west-2.amazonaws.com/pnp_dataset.zip\n",
      "Resolving danylo-ucla.s3.us-west-2.amazonaws.com (danylo-ucla.s3.us-west-2.amazonaws.com)... 52.218.179.34\n",
      "Connecting to danylo-ucla.s3.us-west-2.amazonaws.com (danylo-ucla.s3.us-west-2.amazonaws.com)|52.218.179.34|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1027495996 (980M) [application/zip]\n",
      "Saving to: ‘pnp_dataset.zip’\n",
      "\n",
      "pnp_dataset.zip     100%[===================>] 979.90M  52.2MB/s    in 17s     \n",
      "\n",
      "2022-09-18 19:10:49 (58.0 MB/s) - ‘pnp_dataset.zip’ saved [1027495996/1027495996]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ls pnp_dataset || (wget https://danylo-ucla.s3.us-west-2.amazonaws.com/pnp_dataset.zip && unzip pnp_dataset.zip >/dev/null 2>&1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_images(folder: str):\n",
    "    imgs = []\n",
    "\n",
    "    paths = !find {folder} -type f\n",
    "    paths = sorted(paths)\n",
    "\n",
    "    for path in paths:\n",
    "        with open(path, 'r') as f:\n",
    "            imgs.append(plt.imread(path))\n",
    "            \n",
    "    return np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/bin/zsh: /root/miniconda3/envs/ucla_deeplearning/lib/libtinfo.so.6: no version information available (required by /bin/zsh)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_x \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpnp_dataset/train_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m score_x \u001b[38;5;241m=\u001b[39m load_images(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpnp_dataset/score_x\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m train_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpnp_dataset/train_y.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mload_images\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      8\u001b[0m paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(paths)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m         imgs\u001b[38;5;241m.\u001b[39mappend(plt\u001b[38;5;241m.\u001b[39mimread(path))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(imgs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/bin/zsh: /root/miniconda3/envs/ucla_deeplearning/lib/libtinfo.so.6: no version information available (required by /bin/zsh)'"
     ]
    }
   ],
   "source": [
    "train_x = load_images('pnp_dataset/train_x')\n",
    "score_x = load_images('pnp_dataset/score_x')\n",
    "train_y = np.load('pnp_dataset/train_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_x[0])\n",
    "plt.axis('off')\n",
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_x[1])\n",
    "plt.axis('off')\n",
    "train_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This configures the GPU to be used by Tensorflow.\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1801.04381.pdf\n",
    "# https://keras.io/api/applications/mobilenet/#mobilenetv2-function\n",
    "mobile_net = tf.keras.applications.MobileNetV2(\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3),\n",
    "    weights=\"imagenet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezes the parameters of the MobileNet layers, so they will not update during training.\n",
    "# These parameters are initialized to a pre-trained snapshot using the ImagetNet dataset.\n",
    "mobile_net.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    mobile_net,\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(7, 7)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(\n",
    "            name=\"binary_accuracy\",\n",
    "            threshold=0.5\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=1,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "model_dir = 'pnp_model'\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Once you are ready to make the graded submission,\n",
    "# run the model on the score dataset.\n",
    "score_y_hat = pd.DataFrame(\n",
    "    model.predict(score_x, batch_size=batch_size),\n",
    "    # This is needed to save the file in Parquet format.\n",
    "    columns=['score']\n",
    ")\n",
    "\n",
    "# Now save it to disc as a Parquet file.\n",
    "score_y_hat.to_parquet(f'{model_dir}/score_y_hat.parquet')\n",
    "\n",
    "# Next, let's save the model's definition.\n",
    "import json\n",
    "with open(f'{model_dir}/keras_model.json', 'w') as f:\n",
    "    f.write(json.dumps(json.loads(model.to_json()), indent=True))\n",
    "\n",
    "# Finally, let's save the learned parameters.\n",
    "model.save_weights(f'{model_dir}/keras_parameters.h5')\n",
    "\n",
    "# You now have the following files to be uploaded to Moodle:\n",
    "# 1. This notebook and any other Python code you used to train the final model.\n",
    "# 2. keras_model.json -- the model's definition\n",
    "# 3. keras_parameters.json -- the model's trained parameters\n",
    "# 4. score_y_hat.parquet - the model's output on the score dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucla_deeplearning",
   "language": "python",
   "name": "ucla_deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
