{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Probability Distribution over Sequences\n",
    "\n",
    "Let's consider 1-dimensional sequences, where items are scalars.\n",
    "\n",
    "First, estimate the probability distribution over the next item in the sequence:\n",
    "\n",
    "$ P(x^{\\langle t \\rangle} | x^{\\langle t-1 \\rangle}, x^{\\langle t-2 \\rangle}, \\dots, x^{\\langle 1 \\rangle}) $\n",
    "\n",
    "Then, the probability of a sequence $\\textbf{x}$ is:\n",
    "$$\n",
    "P(\\textbf{x}) = \\prod_{t=1}^{T_x}\n",
    "{P\\big(x^{\\langle t \\rangle} | x^{\\langle t-1 \\rangle}, x^{\\langle t-2 \\rangle}, \\dots, x^{\\langle 1 \\rangle}\\big)}\n",
    "$$\n",
    "\n",
    "Note that $P(x^{\\langle 1 \\rangle})$ is not computable, because there is nothing to condition it with. To avoid this inconvenice, training sequences can be prefixed with Start Token that signals sequence start. Corresponding target value for Start Token is the first item in the sequence. In testing, feeding Start Token will output the probability distribution over the first item in every possible sequence. Similarly, to learn the probability of a sequence ending, training sequences can be suffixed with End Token, which will appear as the last target item but never as an input item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Distribution\n",
    "\n",
    "For example, if the distribution is categorical with K possible outcomes:\n",
    "\n",
    "$\n",
    "i = 1, \\dots, K\n",
    "\\\\\n",
    "\\textbf{x}^{\\langle t \\rangle} \\in \\{0, 1\\}^{K}\n",
    "\\\\\n",
    "$\n",
    "\n",
    "Then the output layer can be softmax activation of the hidden state:\n",
    "$$\n",
    "\\hat{y}^{\\langle t \\rangle}_i\n",
    "= P\\big(\n",
    "    x^{\\langle t \\rangle}_i = 1 |\n",
    "    \\textbf{x}^{\\langle t-1 \\rangle}, \n",
    "    \\textbf{x}^{\\langle t-2 \\rangle}, \n",
    "    \\dots, \n",
    "    \\textbf{x}^{\\langle 1 \\rangle}\n",
    "\\big) \n",
    "= \\frac\n",
    "{\\text{exp}(h^{\\langle t \\rangle}_i)}\n",
    "{\\sum_{j=1}^K{\\text{exp}(h^{\\langle t \\rangle}_j)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Inference\n",
    "\n",
    "It's possible to sample sequences from the learned distribution by feeding the Start Token, randomly choosing an item using the estimated distribution, then feeding this value as the next input item. This process can be repeated until the End Token is sampled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepAR\n",
    "\n",
    "Original paper: Salinas, D., et al. (2019)\n",
    "https://arxiv.org/abs/1704.04110\n",
    "\n",
    "DeepAR is trained with several time series simultaneously, so the model learns across multiple related time series. This allows the model to generalize to new but similar time series where little historical data is available (a task called cold start). Additionally, the model is given auxillary data about each target time series in the form of a covariate time series that is also required to known during the prediction window. Each time series is converted into multiple sequences by randomly choosing the start time. The model's goal is to estimate the conditional probability distribution:\n",
    "\n",
    "$$\n",
    "P\\big(\n",
    "\\textbf{x}_i^{\\langle t_0:T \\rangle} | \n",
    "\\textbf{x}_i^{\\langle 1:t-1 \\rangle}, \n",
    "\\textbf{z}_i^{\\langle 1:T \\rangle}\n",
    "\\big)\n",
    "$$\n",
    "\n",
    "Sequence $\\textbf{x}_i$ is the i-th target sequence, while $\\textbf{z}$ is the i-th covariate sequence. \n",
    "\n",
    "During inference, conditioning window $[1, t_0 - 1]$ is the time period before the forecast is made, \n",
    "while prediction window $[t_0, T]$ is the time period that needs to be forecasted. \n",
    "Therefore, $\\textbf{x}$ is known until and including $t_0 - 1$, while covariate $\\textbf{z}$ is known for the full window $[1, T]$. Each sequence pair $(\\textbf{x}_i, \\textbf{z}_i)$ may cover a different constant-duration period of universal time.\n",
    "\n",
    "Similarly to the example in the previous section, the joint distribution is constructed from chained conditionals:\n",
    "$$\n",
    "P\\big(\n",
    "    \\textbf{x}_i^{\\langle t_0:T \\rangle} | \n",
    "    \\textbf{x}_i^{\\langle 1:t-1 \\rangle}, \n",
    "    \\textbf{z}_i^{\\langle 1:T \\rangle}\n",
    "\\big) \n",
    "= \\prod_{t=1}^{T}\n",
    "{P\\big(\n",
    "    x_i^{\\langle t \\rangle} | x_i^{\\langle 1:t-1 \\rangle}, \\textbf{z}_i^{\\langle 1:T \\rangle}\n",
    "\\big)}\n",
    "$$\n",
    "\n",
    "The model does not learn the distribution directly.\n",
    "Instead the model generates distribution parameters, which are fed into the distribution's PDF/PMF.\n",
    "The choice of the PDF/PMF is driven by the statistical properties of the target sequence's items:\n",
    "* for categorical sequences, the categorical distribution can be modeled with softmax activation\n",
    "* for real-valued sequences, the Gaussian distribution can be learned via mean and standard deviation\n",
    "* for non-negative integer sequences, the Negative Binomial distribution can be learned via mean and shape\n",
    "\n",
    "The distribution's PDF/PMF have to be differentiable, so that the cost function's gradient can be computed, and the model can be trained with gradient descent, since the RNN and the distribution parameters need to be learned together.\n",
    "\n",
    "The cost function is the sum of negative log-likelihood over every time step of every target sequence:\n",
    "\n",
    "$$\n",
    "C = \n",
    "\\sum_{i=1}^N{\n",
    "    \\sum_{t=0}^T{\n",
    "        - \\text{log} \\, \\ell \\big(\n",
    "            x_i^{\\langle t \\rangle} \\, | \\, \\theta(\\textbf{h}_i^{\\langle t \\rangle})\n",
    "        \\big)\n",
    "    }\n",
    "}\n",
    "$$\n",
    "\n",
    "In this definition, $\\theta(\\textbf{h}_i^{\\langle t \\rangle})$ is the function converting the LSTM's hidden state at a particular step of a particular sequence to the probability distribution parameters.\n",
    "Likelihood $\\ell$ is the probability density (for continuous distributions) or the probability mass (for discrete distributions) evaluated at a particular value $x_i^{\\langle t \\rangle}$ given the distribution's parameters.\n",
    "\n",
    "The LSTM cell is initialized with 0 vector, and given 0 vector as the ground truth in the first step. In this step, the cost is calculated against the sequence's first item.\n",
    "\n",
    "In training, the distinction between conditioning and prediction windows is effectively absent due to Teacher Forcing.\n",
    "Ground truth is repetitively fed into the model with a lag of 1 period, while the cost is calculated against the unlagged sequence item. Ground truth is used over both conditioning and prediction windows. Random samples are used only in testing to estimate summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQ-RNN\n",
    "\n",
    "MQ-RNN is trained to predict specific quantiles of the time series. Individual predictions are penalized with quantile loss function:\n",
    "$$ L_q(y, \\hat{y}) = max(0, q(y - \\hat{y}) + max(0, (1-q)(\\hat{y} - y) $$\n",
    "\n",
    "$$\n",
    "L_q(y, \\hat{y}) =\n",
    "\\begin{cases}\n",
    "  q(y - \\hat{y}) & \\text{if } \\hat{y} < y \\\\    \n",
    "  (1-q)(\\hat{y} - y) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "For the i-th target sequence, the total cost over all time steps $t$, quantiles $q$, and prediction horizons $k$ is:\n",
    "\n",
    "$$\n",
    "C_i = \n",
    "\\sum_t\\sum_q\\sum_k{\n",
    "    L_q(y^{\\langle t+k \\rangle}, \\hat{y}_q^{\\langle t+k \\rangle})\n",
    "}\n",
    "$$\n",
    "\n",
    "Decoder consists of two Multi-layer Perceptrons. The global MLP creates context for $K$ prediction horizons, while the local MLP outputs quantiles for a specific prediction horizon $k$. Context consists of a horizon-specific, and a horizon-agnostic parts. Horizon-specific context carries awareness of the distance between Forecast Creation Point $t$ and the prediction horizon $t+k$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf{g}^{\\langle t \\rangle}\n",
    "    & = (\\textbf{c}^{\\langle t+1 \\rangle}, \\dots, \\textbf{c}^{\\langle t+K \\rangle}, \\textbf{c}_a^{\\langle t \\rangle})  \\\\\n",
    "    & = g(\\textbf{h}^{\\langle t \\rangle}, \\textbf{x}_f^{\\langle t: \\rangle})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\textbf{y}}^{\\langle t+k \\rangle} \n",
    "    & = (\\hat{y}_{1}^{\\langle t+k \\rangle}, \\dots, \\hat{y}_{Q}^{\\langle t+k \\rangle}) \\\\\n",
    "    & = f(\\textbf{c}^{\\langle t+k \\rangle}, \\textbf{c}_a^{\\langle t \\rangle}, x_f^{\\langle t+k \\rangle})\n",
    "\\end{align}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collegium",
   "language": "python",
   "name": "collegium"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
