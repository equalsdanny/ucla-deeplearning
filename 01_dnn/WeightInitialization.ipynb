{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why not identical initialization?\n",
    "\n",
    "If we initialize every node within layer $l$ with the same parameters:\n",
    "\n",
    "$ \\forall g, h: $\n",
    "\n",
    "$ \\textbf{w}^{[l]}_{g, :} = \\textbf{w}^{[l]}_{h, :} $\n",
    "\n",
    "$ b^{[l]}_g = b^{[l]}_h $\n",
    "\n",
    "This implies that each node within layer $l$ activates identically:\n",
    "\n",
    "$ \\forall g, h: $\n",
    "\n",
    "$ z^{[l]}_{s, g} = \\textbf{a}^{[l-1]}_{s, :} \\cdot \\textbf{w}^{[l]T}_{g, :} + b_g^{[l]} $\n",
    "\n",
    "$ z^{[l]}_{s, h} = \\textbf{a}^{[l-1]}_{s, :} \\cdot \\textbf{w}^{[l]T}_{h, :} + b_h^{[l]} $\n",
    "\n",
    "$ z^{[l]}_{s, g} = z^{[l]}_{s, h} $\n",
    "\n",
    "$ a^{[l]}_{s, g} = f(z^{[l]}_{s, g}) = f(z^{[l]}_{s, h}) = a^{[l]}_{s, h} $\n",
    "\n",
    "This implies that the gradient of all nodes within layer $l$ is identical:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "    \\forall g, h: & \\\\\n",
    "    \\frac {\\partial C_s} {\\partial w^{[l]}_{g, n}} \n",
    "    & = \\frac {\\partial C_s} {\\partial a^{[l]}_{s, g}} \n",
    "    * f'(z^{[l]}_{s, g})\n",
    "    * a^{[l-1]}_{s, n} \n",
    "    \\\\\n",
    "    \\frac {\\partial C_s} {\\partial w^{[l]}_{h, n}} \n",
    "    & = \\frac {\\partial C_s} {\\partial a^{[l]}_{s, h}} \n",
    "    * f'(z^{[l]}_{s, h})\n",
    "    * a^{[l-1]}_{s, n} \n",
    "    \\\\\n",
    "    \\frac {\\partial C_s} {\\partial w^{[l]}_{g, n}} \n",
    "    & = \\frac {\\partial C_s} {\\partial w^{[l]}_{h, n}}  \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that the upstream gradient has to be identical too.\n",
    "This is true if the upstream layer is also identically initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glorot Initialization\n",
    "Source: Understanding the difficulty of training deep feedforward neural networks (Glorot, X., and Bengio Y., 2010).\n",
    "http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf\n",
    "\n",
    "$$ W_i \\sim U\\left( -\\sqrt{\\frac{6}{n_{in} + n_{out}}}, \\sqrt{\\frac{6}{n_{in} + n_{out}}} \\right) $$\n",
    "$$ n_{in} (n_{out}) = \\text{count of input (output) connections} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mGlorotUniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "The Glorot uniform initializer, also called Xavier uniform initializer.\n",
       "\n",
       "It draws samples from a uniform distribution within [-limit, limit]\n",
       "where `limit` is `sqrt(6 / (fan_in + fan_out))`\n",
       "where `fan_in` is the number of input units in the weight tensor\n",
       "and `fan_out` is the number of output units in the weight tensor.\n",
       "\n",
       "Args:\n",
       "  seed: A Python integer. Used to create random seeds. See\n",
       "    `tf.compat.v1.set_random_seed` for behavior.\n",
       "  dtype: Default data type, used if no `dtype` argument is provided when\n",
       "    calling the initializer. Only floating point types are supported.\n",
       "References:\n",
       "    [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)\n",
       "    ([pdf](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf))\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "DEPRECATED FUNCTION ARGUMENTS\n",
       "\n",
       "Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
       "Instructions for updating:\n",
       "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.python.ops.init_ops import GlorotUniform\n",
    "?GlorotUniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# He Initialization\n",
    "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification (He, K., et al., 2015)\n",
    "https://arxiv.org/abs/1502.01852\n",
    "\n",
    "$$ W_i \\sim N\\left( 0, \\sqrt{\\frac{2}{n_{in}}} \\right) $$\n",
    "$$ n_{in} = \\text{count of input connections} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mhe_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "He normal initializer.\n",
       "\n",
       "It draws samples from a truncated normal distribution centered on 0\n",
       "with standard deviation (after truncation) given by\n",
       "`stddev = sqrt(2 / fan_in)` where `fan_in` is the number of\n",
       "input units in the weight tensor.\n",
       "\n",
       "Arguments:\n",
       "    seed: A Python integer. Used to seed the random generator.\n",
       "\n",
       "Returns:\n",
       "    An initializer.\n",
       "\n",
       "References:\n",
       "    [He et al., 2015]\n",
       "    (https://www.cv-foundation.org/openaccess/content_iccv_2015/html/He_Delving_Deep_into_ICCV_2015_paper.html)\n",
       "    # pylint: disable=line-too-long\n",
       "    ([pdf](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf))\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.python.ops.init_ops import he_normal\n",
    "?he_normal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucla_deeplearning",
   "language": "python",
   "name": "ucla_deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
